\documentclass{ransom}

<%

load 'eruby_ransom.rb'

author = "petronius"
treebank = TreeBank.new(author)
freq_file = nil # "lemmas/#{author}_freq.json"
latin_genos = Genos.new('la')
db = GlossDB.from_genos(latin_genos)
latin_wikt = WiktionaryGlosses.new(latin_genos)
if latin_wikt.invalid then latin_wikt=nil end
core = json_from_file_or_die("core/latin.json").keys # array containing lemmas not to put in vocab lists, because they're in core vocab in back
latin = Epos.new("text/petronius/satyricon_62.txt","latin",false,genos:latin_genos)
translation = Epos.new("text/petronius/satyricon_62_firebaugh.txt","latin",false,genos:Genos.new('en',is_verse:false),postfilter:lambda { |s| Epos.strip_pg_footnotes(s) })

notes = []

stuff = treebank,freq_file,latin,translation,notes,core

%>

\begin{document}

\pagestyle{fancy}

<%

matches = [
  [ "Forte dominus Capuae exierat ad scruta", "It so happened that our master" ],
  [ "In larvam intravi", "I looked like a ghost" ],
  [ "Intellexi illum versipellem esse>", "I hope your geniuses will all get after me if I lie>" ],

]

format = ENV['FORMAT']
if format.nil? then $stderr.print "FORMAT environment variable not set\n"; exit(-1) end
if !(['whole','booklet_short'].include?(format)) then $stderr.print "FORMAT environment variable set to illegal value #{format}\n"; exit(-1) end
if format=='booklet_short' then matches = matches[0..17] end

dry_run = !(ENV['DRY_RUN'].nil?)

if Options.if_prose_trial_run then
  print %q(\begin{foreignprose}),"\n"
  count_files = 0
  count_paragraphs = 0
  latin.get_contents.each { |file_contents|
    file_offset = 0
    paras_and_delimiters = file_contents.split(/(\s*(?:\n[ \t]*){2,}\s*)/) # even indices=paragraphs, odd=delimiters
    if paras_and_delimiters.length%2==1 then paras_and_delimiters.push('') end # doesn't end with a delimiter
    0.upto(paras_and_delimiters.length/2-1) { |i| # guaranteed to be divisible by 2, see above
      paragraph,delim = [paras_and_delimiters[2*i],paras_and_delimiters[2*i+1]]
      if paragraph!='' then
        print "\n\n%%%%%% paragraph #{count_paragraphs} %%%%%%\n\n"
        print WhereAt.adorn_string_with_commands_to_write_pos_data(paragraph,paragraph_count:count_paragraphs,
                              file_count:count_files,starting_offset:file_offset),"\n\n"
      end
      file_offset += paragraph.length+delim.length
      count_paragraphs += 1
    }
    count_files += 1
  }
  print %q(\end{foreignprose}),"\n"
else

=begin
[
{"flags":["para"],"lines":[["Forte dominus Capuae exierat ad scruta scita expedienda.",0,57],["Nactus ego occasionem persuadeo hospitem nostrum, ut",57,110],["mecum ad quintum miliarium veniat. Erat autem miles,",110,163],["fortis tanquam Orcus. Apoculamus nos circa gallicinia; luna",163,223],["lucebat tanquam meridie. Venimus inter monimenta: homo",223,278],["meus coepit ad stelas facere; sedeo ego cantabundus et stelas",278,340],["numero.",340,348]]},
{"flags":["para"],"lines":[["Deinde ut respexi ad comitem, ille exuit se et omnia",0,53],["vestimenta secundum viam posuit. Mihi anima in naso esse;",53,111],["stabam tanquam mortuus. At ille circumminxit vestimenta",111,167],["sua, et subito lupus factus est. Nolite me iocari putare;",167,225],["ut mentiar, nullius patrimonium tanti facio. Sed, quod",225,280],["coeperam dicere, postquam lupus factus est, ululare coepit",280,339],["et in silvas fugit. Ego primitus nesciebam ubi essem; deinde",339,400],["accessi, ut vestimenta eius tollerem: illa autem lapidea facta",400,463],["sunt. Qui mori timore nisi ego? Gladium tamen strinxi et",463,520],["<in tota via> umbras cecidi, donec ad villam amicae meae",520,577],["pervenirem.",577,589]]},
...
]
  def initialize(g1,g2,t1,t2,foreign,translation,max_chars:5000,length_ratio_tol_factor:1.38)
    # Foreign and translation are Epos objects, which should have non-nil genos with is_verse set correctly.
    # G1, g2, t1, and t2 are references for input to Epos initializer. If a text is verse, then these should be
    # of the form [book,line]. If prose, then they should be either word globs or hard refs.
    # sanity checks:
    #   max_chars -- maximum length of translated text
    #   length_ratio_expected -- expected value of length of translation divided by length of foreign text
    #   length_ratio_tol_factor -- tolerance factor for the above ratio
=end

  paras = json_from_file_or_die("demo.para") # FIXME -- hardcoded filename
  paras.push(nil) # marker for end
  pages = []
  page = [] # accumulates paragraphs until a page break
  paras.each { |p|
    # p is either a paragraph or part of a paragraph that has been split by a page break
    page.push(p) unless p.nil?
    if p.nil? || p['flags'].include?('page') then pages.push(page); page=[] end # flush page
  }
  matches_latin = []
  matches_translation = []
  0.upto(matches.length-1) { |i|
    x = latin.word_glob_to_hard_ref(matches[i][0])
    if x[0].nil? then raise "error in word glob #{matches[i][0]}; for better debugging info, add code as in eruby_ransom.rb, Bilingual class" end
    matches_latin.push(x[0])
    x = translation.word_glob_to_hard_ref(matches[i][1])
    if x[0].nil? then raise "error in word glob #{matches[i][1]}" end
    matches_translation.push(x[0])
  }
  layouts = []
  pages.each { |page|
    foreign_offset_1 = page[0]['lines'][0][1]
    foreign_offset_2 = page[-1]['lines'][-1][2]
    foreign_hr1 = [0,foreign_offset_1] # assumes a single file
    foreign_hr2 = [0,foreign_offset_2]
    starting_ch = 0
    dry_run = false
    t1 = latin.interpolate_bitext(translation,matches_latin,matches_translation,foreign_hr1)
    t2 = latin.interpolate_bitext(translation,matches_latin,matches_translation,foreign_hr2)
    layouts.push([Bilingual.new(foreign_hr1,foreign_hr2,t1,t2,latin,translation,length_ratio_tol_factor:2.0),starting_ch,dry_run])
  }
  vocab_by_chapter = []
  0.upto(layouts.length-1) { |i|
    bilingual,starting_ch,dry_run = layouts[i]
    if i<layouts.length-2 then next_layout=layouts[i+1][0] else next_layout=nil end
    four_page_layout(stuff,latin.genos,db,latin_wikt,bilingual,next_layout,vocab_by_chapter,dry_run:dry_run)
  }
  1.upto(vocab_by_chapter.length-1) { |ch|
    filename = sprintf("vocab_ch_%02d.txt",ch)
    File.open(filename,'w') { |f|
      f.print vocab_by_chapter[ch].join("\n")+"\n"
    }
  }
end

%>

%=============================================================================
%    end of file
%=============================================================================

% \end{document} gets generated by eruby
